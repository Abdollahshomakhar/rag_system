{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvjMMEq5wV9z"
   },
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "! pip install -U bitsandbytes\n",
    "! pip install -U accelerate transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ASr3-C3QxWVd"
   },
   "outputs": [],
   "source": [
    "! pip install langchain_community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xGmb3nOEvXKi"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from torch import cuda, bfloat16\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EizP4BZ6w9sK",
    "outputId": "dff103c2-655f-4b5a-a55c-b88f7504443d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU:  1\n",
      "GPU Name:  Tesla T4\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of GPU: \", torch.cuda.device_count())\n",
    "print(\"GPU Name: \", torch.cuda.get_device_name())\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "690403e0b99e43c6afb81ac2de3a9185",
      "bcd8f4a4f6e043c7a14dbfae80fc4e86",
      "869ed42cffee4cf39b9140c2655ec3f5",
      "68a39436d74a4c26bc286f4c3a5ebcd9",
      "4ffefe5c9be3451e9e3834612f44c432",
      "29f8e89fc78e4b9f9a2c3c5f42fe2a0a",
      "a287044210cc4159b2823aa4e5d47629",
      "2f51db2c038b48cfb38a50b3751648d3",
      "7c4670727b2e4341b5d579b9b74eddcf",
      "bf8826b3754145c79530af2cbcf0d939",
      "b0e5c4e9c91f4c9481bc5412d5e0b7b8",
      "94045ebcee20439ca8864ec09060b4e9",
      "c42f686161e84d5eadd0cc85a5af261c",
      "7cf6f4149ed24ead87cbde9eeccb8b18",
      "a678b9f80eb844579c2b337e9a9852a3",
      "8eecbde1881b4c16b295f6ffa8f107e1",
      "c6ed7e2aba564fddb0b5981dd56bb9c4",
      "f5f9978c803d40409529f986ad1b5a61",
      "64497a59ca4546c18ba7247907b9b25e",
      "fadb2c6218f846f7960075a344875203"
     ]
    },
    "id": "9MOHkprMwx9A",
    "outputId": "91a2a873-a519-4a9f-cde4-27ae8020f5fb"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nq9ZvqtrwAZ-",
    "outputId": "53b2b3a1-d9ab-4a92-9fb5-596131ad6fbf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_id = 'google/gemma-2b-it'\n",
    "token = \"YOUR TOKEN\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token =token)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # رفع خطای padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyFpu348xuCE"
   },
   "outputs": [],
   "source": [
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "b44fcdc6237749b5a37139829b4ed14f",
      "2b1c6960eabc439fb89c5c8185cf8772",
      "4df78f6d031c42c0bd7f7598c4bbcfe8",
      "d2368817627a4607bbe2c2fe2ae14961",
      "c84895a6ddba45159d5ff64a12ec36d1",
      "f8f49001fba843ba8088823279a0fafb",
      "0aad1f05fa1c4073a7076b0c51e96330",
      "cec97d0fbd784568b1f4f7e155517f98",
      "169f10c23d054c45a84609b419a54df0",
      "1fa33cbc44fa4c68ad9c3b6893add82f",
      "a24ec97d45ea442bafc14e21d9033510"
     ]
    },
    "id": "Ty-5Z45gxytK",
    "outputId": "4e2ba02a-9d2f-46d6-9835-003509d687ae"
   },
   "outputs": [],
   "source": [
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "   model_id,\n",
    "    trust_remote_code=True,\n",
    "    max_new_tokens=1024\n",
    ")\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    token=\"YOUR TOKEN\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o_qM3vuQyasw",
    "outputId": "00554ad6-7c70-4a12-fc95-bb26cb5cddf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tell  me a scary  story about a haunted house.\n",
      "\n",
      "The old Victorian house, known as Blackwood Manor, stood alone on a hill overlooking the town. Its peeling paint and crooked chimney sent shivers down the spine of every resident. The locals whispered about the house's dark history, but no one dared to set foot inside.\n",
      "\n",
      "One stormy night, a group of teenagers decided to explore the manor. They braved the creaking doors and unlocked the front door. The air grew thick with a musty smell, and\n"
     ]
    }
   ],
   "source": [
    "prompt = \"tell  me a scary  story\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FIQTxoeg0630",
    "outputId": "a0d99c35-5fd7-47e1-d810-4c4618e8f5dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': tensor([[    2,  4361,   139,   504,   476, 32864,   139, 15732]],\n",
       "        device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')},\n",
       " transformers.tokenization_utils_base.BatchEncoding)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs,type(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b_WiDSiXyLcT",
    "outputId": "c24e15a8-67b4-4bff-a822-c1bcc3587585"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "query_pipeline = transformers.pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        torch_dtype=torch.float16,\n",
    "        max_length=1024,\n",
    "        device_map=\"auto\",)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7DsWkrU_yRPl"
   },
   "outputs": [],
   "source": [
    "def test_model(tokenizer, pipeline, message):\n",
    "    sequences = pipeline(\n",
    "        message,\n",
    "        do_sample=True,\n",
    "        top_k=10,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_length=200,)\n",
    "\n",
    "\n",
    "    question = sequences[0]['generated_text'][:len(message)]\n",
    "    answer = sequences[0]['generated_text'][len(message):]\n",
    "\n",
    "    return f\"Question: {question}    nAnswer: {answer}   {sequences}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ydWweFcDyRMN"
   },
   "outputs": [],
   "source": [
    "response = test_model(tokenizer,\n",
    "                    query_pipeline,\n",
    "                   \"tell  me a scary  story\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M4uL1NJ11DMs"
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "id": "FVI6BmJs1bIl",
    "outputId": "cc2734f8-99cb-4118-88fa-77bfc6573dfb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-193697960.py:1: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=query_pipeline)\n",
      "/tmp/ipython-input-193697960.py:4: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm(prompt=question)\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'tell  me a scary  story about a young woman who was trapped in a cage in the basement.\\n\\nThe door to her room was locked, but she managed to break free and escape through a small hole in the floorboards. She ran down the hallway and into the unknown, where she encountered a chilling sight that sent shivers down her spine.\\n\\nA single, withered rose lay at the dead end of the hallway, its petals twisted and gnarled beyond recognition. It was a symbol of the darkness that lurked in the shadows, a stark reminder of her confinement.\\n\\nAs she ventured deeper into the basement, she heard a faint rustling sound coming from the shadows. It was a sound that sent chills down her spine, a sound that seemed to come from everywhere and nowhere at once. It was the sound of something moving, something that promised to end her nightmare.\\n\\nShe hesitated, her heart pounding in her chest. She knew that she should leave, that the darkness she had escaped was too dangerous. But she was trapped, a captive in her own nightmare. She had nowhere to go but forward, and she had to find a way to escape.\\n\\nFinally, she gathered her courage and started to crawl through the hole in the floorboards. It was a long and arduous journey, but she finally broke free. She stood up, her legs shaky and trembling, but she was alive. She was free.\\n\\nShe ran out of the basement and into the hallway, her heart pounding in her chest. She looked back at the basement, but she could see no sign of her earlier tormentor. She had escaped, but she knew that the darkness that had trapped her would never truly leave her.\\n\\nShe knew that she would have to live with this fear for the rest of her life, but she knew that she would never forget her escape, nor the chilling sight she had encountered in the basement.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = HuggingFacePipeline(pipeline=query_pipeline)\n",
    "\n",
    "question =  \"tell  me a scary  story\"\n",
    "response = llm(prompt=question)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ImikeESi3ueJ"
   },
   "outputs": [],
   "source": [
    "! pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bG3Y1leX2npv"
   },
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"/content/Abstract.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOE1rOOW2wNV"
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=128)\n",
    "all_splits = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424,
     "referenced_widgets": [
      "c3b05846d3d44d6e8a2d2abd0bf7c893",
      "843375f0fc884c45815010a48bd8d973",
      "754f2904851040dba87588cca7e75c00",
      "c4dd5d7801bb44749bbce91c91dc3781",
      "186f849b78bf4fcc8e3262fa510d5709",
      "aac6ba54c48645b6bc29191bfd017fda",
      "5fe21db64e82453dadbfea6987c1bc73",
      "98e99505b852435cb9ba9d9777d40406",
      "3b4630752515449a83cdf57f33a21803",
      "71e1394e1c384e1b80f854d6c9ceff7f",
      "55581952190f479c922d0f9751c24257",
      "bd437d97de30445ba39267d32c5e2fea",
      "23ef28a9fc8442b9aa60456bd138827d",
      "588ab5e522694c4c87913c4927b6a738",
      "70d686c3dbf5480ca1c5e017cc13a056",
      "2ffebe83b50c4d35a3bfdb8c8aee5915",
      "47ca64a7bc0d456db366f42a1012078f",
      "b47535022ba54b1391786c09f577f40f",
      "14ed60c274e743cc8bad1f66103bee31",
      "77f44c23c4484f2090fdf955eecdcbac",
      "5770ebc16eb7429bb739545ae2da2030",
      "62fb5bc2873f4b6c9040ddf7f6388454",
      "58694cfebf094888abeb7ffe7e7aadc6",
      "ffbf9525b75c40e3b6a442d9ca824a32",
      "80262245cb6f4dfdbefba64b705cddde",
      "d8c9aa87f4ee4f23b37d44d6caef6ab3",
      "747179d42b004edf9a4156e0f84f6e0c",
      "3edad7647bb94c41be621d22d2a46c0e",
      "3963a0ad11f74051a131a32f6404a20f",
      "5a46a6756c7d41f68fd07e873b3ee07c",
      "372bc7b839da480890feac65862efb00",
      "badcb0a90b354e0bb74b3f7bfc20469f",
      "f2dd08e17eef41dbb9bb153034c42573",
      "f64a65bc5f304dfc9db4a26133d1215a",
      "5364559684b14d219260d9526c16eedf",
      "0569b842b061478bb2daf55f48232394",
      "cda33705af40442c8e0300ca2ee2c1e7",
      "fc622e6917a04488b8a763a2ee256a95",
      "d71e5f63a61f41deaa5ab0d6402b066b",
      "3dd53c60e627476ab200aaf08b1add62",
      "246ebb9a5946454ca27efd168f8d3629",
      "b83cc732588a4e6886534767a4136680",
      "2a02f9d01c994b3298f187e1aa379647",
      "03262a11c16a4f3b8586680ce4aa5ab1",
      "dfb23466a46e4e7e91bb76e7d06ea445",
      "196b342d4e9e4f81b745a13a0a983d35",
      "43d2c9de404048f392e62b7d3fb1d982",
      "3efe909d5d6d4393860cdf74b5d773f2",
      "8f05f605b200466493c2b41fa5046d84",
      "bbe28715b65847009951bd7959fb846b",
      "4a3b99a0367e4e13b148d9e89e6f4d45",
      "1d027338f7834db28d10552b1c652e48",
      "0c3d7031448741dda48d9c6008ecd676",
      "aa918e09f98745dca9831aaace4b0290",
      "23e3799ecfed448f930e027fe6893ed3",
      "2725f233b7ff4bb6afeb61ee2e2ca833",
      "6a6fb9d21ffa4ab9805084cefd793527",
      "2131d0cceeff4faa834e478d9db81c3a",
      "e436629c38b7453ea82b882ae3eb7e6e",
      "ebb4fa59cdee4a5bbb8a906d545bc57b",
      "cb8a9265ad7c48418c23987612075151",
      "be567e36afe54eabbd63bd09789aa3be",
      "ee905f89cc1a43cbb937427dacbeda4f",
      "d60838abb5854efeaa51659e54661749",
      "331094fc68214a5ba0c7c421ae63bc1d",
      "8f3bbe23140b42ddabffedd39c8f0ba0",
      "d36c666d58c64a69913db930d515ab08",
      "480eb50ee97e48598518c3c25118e81c",
      "6dcd6050f7cf4f5bbdf91333c15a45e5",
      "741e06d88a6c40358ebaec375458b7a7",
      "f183efd8cb3a48a7a32776d558b6b9a1",
      "4fb214a14ffb41c4878301676babb162",
      "494fcac8f4a54284ad534fd766264c61",
      "91a8515052c342e09d6baf0dbfb5b53c",
      "caf2b78ae664456bb048dda7d1276c26",
      "881551b245ac4b43976b0ba1761383c6",
      "e27aef19b3874b5585dffee2243327c8",
      "3f861953b7e64fb297d3f0e1ca871598",
      "ab1b68c168d244b98cbe472e332ec59a",
      "abf3e4af28d14ea490cc7a218d6f51ca",
      "d437634c006c440589109e6076cf1ec5",
      "697f9f4536be4fa0bd437bae7d8df402",
      "0e98a56cf7794f608255d1c7481181c0",
      "9d8d2653eccd4a6fbe88d68c05878427",
      "8f301857d40e4d3a87aa182bf7f537ed",
      "45c07127ed444d98847ce4686403b9d2",
      "e854f61040b9497cab7711447b5a4d0a",
      "02380605d3024068989f28ca5606c865",
      "847c118a53ff46419826a198adc6f46e",
      "79b531ec7302438dacd665131cc32117",
      "d1fdd2441e54414da3d0af0299b06486",
      "9460344d79de44d0bc187ace11ce8271",
      "65215558213b45bb9860e99c3840f666",
      "360608a783f84484bbe671ef2cd7efc0",
      "3bfeb0b17e9c43fa860a61fa8448cc10",
      "d706a970ba604bf9ac0d41d40329b08c",
      "530f5a9233724291bf105cbefc4a9821",
      "d4ba2b03d2ad4a07ab337c3cc8001ec6",
      "358ee9d18ab248e4a86eac7a6ddc99ff",
      "adca68c8ece64809920123a0ab25547a",
      "b4b38e4037ab4cf19a77e409054de0f1",
      "6dcef972d38a4c3daed0d6162bea5248",
      "b68c63c6728a464c9b1c1ab56fbef480",
      "2ba46f0e04a248a3a92b04e2e9a1d661",
      "8f7b718252f84844a71937e145500186",
      "a0a7e412e45f4194bf4c2dac4db90a56",
      "559b609d0a1d4ba8b3eef0a0df07de7c",
      "1604bdd8d0274eb9ad61e03bce9f6fcb",
      "fc1d4e8d74074e1f821d51b0fb45b8f0",
      "5f95166dc8ca40968051e67fe2f4ae1c",
      "fe9315a9cf1143a099eb8d1939e53a16",
      "81c8b806835c4b6abf8d35c44603c88d",
      "cf31922b2b33414c8b9afe76762955a6",
      "03fd815e86d14e26b20cb26eee2a108f",
      "13153b3936e840df8eb530f3d30e6d7e",
      "c2f426feb7c3405fb12a001c90552ef5",
      "c62909801e2a4965937a26d02a85d9ef",
      "d56bd96ffca3466f9f5df565852edf87",
      "34297b05d8cd40e59a88de809b25bc37",
      "af8cd4a08e1f469fb692aceaed13637c",
      "f3f1092f777849c1b9a6a0a293b47701"
     ]
    },
    "id": "EOP5YQFb34x-",
    "outputId": "f481760f-5906-41de-fd84-82384493a226"
   },
   "outputs": [],
   "source": [
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "model_kwargs = {\"device\": \"cuda\"}\n",
    "\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_M6UdyIC8gmU"
   },
   "outputs": [],
   "source": [
    "! pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PcpJaC7j4mVe"
   },
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(documents=all_splits, embedding=embeddings, persist_directory=\"chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LRALn_Kk4utn"
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDbSuu5Y40c6"
   },
   "outputs": [],
   "source": [
    "def test_rag(qa, query):\n",
    "\n",
    "    response = qa.run(query)\n",
    "    full_response =  f\"Question: {query}\\nAnswer: {response}\\nTotal time\"\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "2qjAhj384_tj",
    "outputId": "aaf8c2ff-4ea8-4e4b-9ce9-2ec1fd01eac9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Question: what is the category about say it simple\\nAnswer: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nAbstract: Recommendation System is an information filtering system which seeks to predict the \\n“liking” of a user for an item, with the aim to suggest the user those items which he/she is most \\nlikely to select/buy. The focus of this paper is on rating prediction whose main objective is to \\npredict the ratings the current user is going to give to the items which are yet to be \\nrated/viewed by him/her. This paper uses a collaborative filtering based approach for generating \\nrecommendation, and the model used is a clustering-based model. In this approach all the \\nexisting users are clustered using whale optimization technique, instead of traditional clustering \\napproaches like k-means, EM algorithm, etc. The appropriate cluster is then identified for the \\nactive user, and the ratings of the active user are predicted based on ratings given by other \\nusers belonging to the same cluster. Different measures like MAE, SD, RMSE and t-value are\\n\\nusers belonging to the same cluster. Different measures like MAE, SD, RMSE and t-value are \\nused for performance analysis of the proposed method and the results obtained are found to be \\nhighly accurate.\\n\\nQuestion: what is the category about say it simple\\nHelpful Answer: The category about this paper is about recommendation systems, which are systems that are used to help people find items or services that they are interested in.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what is the category about say it simple\"\n",
    "test_rag(qa, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "jVeoc7iw9RHe",
    "outputId": "4fb60dd6-8b6a-4eb9-c29a-c70b70b511a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Question: what is the topic just say one word\\nAnswer: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nAbstract: Recommendation System is an information filtering system which seeks to predict the \\n“liking” of a user for an item, with the aim to suggest the user those items which he/she is most \\nlikely to select/buy. The focus of this paper is on rating prediction whose main objective is to \\npredict the ratings the current user is going to give to the items which are yet to be \\nrated/viewed by him/her. This paper uses a collaborative filtering based approach for generating \\nrecommendation, and the model used is a clustering-based model. In this approach all the \\nexisting users are clustered using whale optimization technique, instead of traditional clustering \\napproaches like k-means, EM algorithm, etc. The appropriate cluster is then identified for the \\nactive user, and the ratings of the active user are predicted based on ratings given by other \\nusers belonging to the same cluster. Different measures like MAE, SD, RMSE and t-value are\\n\\nusers belonging to the same cluster. Different measures like MAE, SD, RMSE and t-value are \\nused for performance analysis of the proposed method and the results obtained are found to be \\nhighly accurate.\\n\\nQuestion: what is the topic just say one word\\nHelpful Answer: Collaborative filtering based approach for generating recommendations.\\nTotal time\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what is the topic just say one word\"\n",
    "test_rag(qa, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "L-nnCJgi-GI4",
    "outputId": "6fd2fa55-e24b-4b28-d350-8d3f6f1f7131"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Question: just say one word\\nAnswer: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nAbstract: Recommendation System is an information filtering system which seeks to predict the \\n“liking” of a user for an item, with the aim to suggest the user those items which he/she is most \\nlikely to select/buy. The focus of this paper is on rating prediction whose main objective is to \\npredict the ratings the current user is going to give to the items which are yet to be \\nrated/viewed by him/her. This paper uses a collaborative filtering based approach for generating \\nrecommendation, and the model used is a clustering-based model. In this approach all the \\nexisting users are clustered using whale optimization technique, instead of traditional clustering \\napproaches like k-means, EM algorithm, etc. The appropriate cluster is then identified for the \\nactive user, and the ratings of the active user are predicted based on ratings given by other \\nusers belonging to the same cluster. Different measures like MAE, SD, RMSE and t-value are\\n\\nusers belonging to the same cluster. Different measures like MAE, SD, RMSE and t-value are \\nused for performance analysis of the proposed method and the results obtained are found to be \\nhighly accurate.\\n\\nQuestion: just say one word\\nHelpful Answer: The focus of this paper is on rating prediction.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"just say one word\"\n",
    "test_rag(qa, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "id": "UibAo2fG_EVu",
    "outputId": "ad3eb183-6cc8-4ec6-c614-4d1efa7c71b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Question: what is this about\\nAnswer: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nAbstract: Recommendation System is an information filtering system which seeks to predict the \\n“liking” of a user for an item, with the aim to suggest the user those items which he/she is most \\nlikely to select/buy. The focus of this paper is on rating prediction whose main objective is to \\npredict the ratings the current user is going to give to the items which are yet to be \\nrated/viewed by him/her. This paper uses a collaborative filtering based approach for generating \\nrecommendation, and the model used is a clustering-based model. In this approach all the \\nexisting users are clustered using whale optimization technique, instead of traditional clustering \\napproaches like k-means, EM algorithm, etc. The appropriate cluster is then identified for the \\nactive user, and the ratings of the active user are predicted based on ratings given by other \\nusers belonging to the same cluster. Different measures like MAE, SD, RMSE and t-value are\\n\\nusers belonging to the same cluster. Different measures like MAE, SD, RMSE and t-value are \\nused for performance analysis of the proposed method and the results obtained are found to be \\nhighly accurate.\\n\\nQuestion: what is this about\\nHelpful Answer: This paper proposes an approach for recommendation system that uses whale optimization \\ntechnique for generating recommendations. It focuses on rating prediction, which is the main objective \\nof recommendation systems. This approach uses a clustering-based model for recommendation, and it employs whale \\noptimization technique to cluster users based on their similarity. The results of this approach are highly \\naccurate, demonstrating the effectiveness of the proposed method.\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what is this about\"\n",
    "test_rag(qa, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "mTKMUCr-_U_9",
    "outputId": "934c5829-9d3b-4f6b-ba07-c1e5952f86f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nAbstract: Recommendation System is an information filtering system which seeks to predict the \\n“liking” of a user for an item, with the aim to suggest the user those items which he/she is most \\nlikely to select/buy. The focus of this paper is on rating prediction whose main objective is to \\npredict the ratings the current user is going to give to the items which are yet to be \\nrated/viewed by him/her. This paper uses a collaborative filtering based approach for generating \\nrecommendation, and the model used is a clustering-based model. In this approach all the \\nexisting users are clustered using whale optimization technique, instead of traditional clustering \\napproaches like k-means, EM algorithm, etc. The appropriate cluster is then identified for the \\nactive user, and the ratings of the active user are predicted based on ratings given by other \\nusers belonging to the same cluster. Different measures like MAE, SD, RMSE and t-value are\\n\\nusers belonging to the same cluster. Different measures like MAE, SD, RMSE and t-value are \\nused for performance analysis of the proposed method and the results obtained are found to be \\nhighly accurate.\\n\\nQuestion: what is this about\\nHelpful Answer: This paper is about a recommendation system that predicts the ratings the current user is going to give to the items which are yet to be rated/viewed by him/her.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what is this about\"\n",
    "test_rag(qa, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9GhXTMyz_n0l"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
